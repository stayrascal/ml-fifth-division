{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_file = '../data/heart.csv'\n",
    "origin_data = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(293, 9) (293, 2)\n"
     ]
    }
   ],
   "source": [
    "def load_data(data = origin_data, stragy = 2):\n",
    "    positive_example = data[data['chd'] == 1]\n",
    "    negitive_example = data[data['chd'] == 0]\n",
    "\n",
    "    if stragy == 1:\n",
    "        positive_example = pd.concat([positive_example, positive_example])\n",
    "    elif stragy == 2: \n",
    "        negitive_example = data[data['chd'] == 0]\n",
    "        negitive_index = random.sample(list(negitive_example.index.values), len(positive_example))\n",
    "        negitive_example = negitive_example.ix[negitive_index]\n",
    "\n",
    "    positive_msk = np.random.rand(len(positive_example)) < 0.9\n",
    "    negitive_msk = np.random.rand(len(negitive_example)) < 0.9\n",
    "    \n",
    "    while np.abs(len(positive_example[positive_msk]) - len(negitive_example[negitive_msk])) > 10:\n",
    "        positive_msk = np.random.rand(len(positive_example)) < 0.9\n",
    "        negitive_msk = np.random.rand(len(negitive_example)) < 0.9\n",
    "    \n",
    "    train_dataset = pd.concat([positive_example[positive_msk], negitive_example[negitive_msk]])\n",
    "    test_dataset = pd.concat([positive_example[~positive_msk], negitive_example[~negitive_msk]])\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def normaliztion(dataset):\n",
    "    return dataset.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)), axis=0)\n",
    "\n",
    "def transfer_famhist(dataset):\n",
    "    tmp = dataset.replace({'famhist':{'Present':1, 'Absent':0}})\n",
    "    return normaliztion(tmp).values\n",
    "\n",
    "def to_one_hotting(data, num_lables=2):\n",
    "    return (np.arange(num_lables) == data[:,None]).astype(np.float32)\n",
    "\n",
    "def generate_data(dataset):\n",
    "    data = dataset.iloc[:,0:9]\n",
    "    labels = dataset['chd']\n",
    "    return randomize(transfer_famhist(data), to_one_hotting(labels.values))\n",
    "\n",
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "\n",
    "train_dataset, test_dataset = load_data(origin_data)\n",
    "\n",
    "train_data, train_label = generate_data(train_dataset)\n",
    "test_data, test_label = generate_data(test_dataset)\n",
    "\n",
    "print(train_data.shape, train_label.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define paramaters for the model\n",
    "learning_rate = 0.01\n",
    "batch_size = 16\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.8450903561380174 at epoch:0  and accuracy is : 0.444444444444\n",
      "Average loss:0.759326352013482 at epoch:1  and accuracy is : 0.555555555556\n",
      "Average loss:0.6988345517052544 at epoch:2  and accuracy is : 0.62962962963\n",
      "Average loss:0.656263111366166 at epoch:3  and accuracy is : 0.592592592593\n",
      "Average loss:0.6258349120616913 at epoch:4  and accuracy is : 0.62962962963\n",
      "Average loss:0.6035914503865771 at epoch:5  and accuracy is : 0.592592592593\n",
      "Average loss:0.587040364742279 at epoch:6  and accuracy is : 0.62962962963\n",
      "Average loss:0.5745855818192164 at epoch:7  and accuracy is : 0.592592592593\n",
      "Average loss:0.5651479131645627 at epoch:8  and accuracy is : 0.592592592593\n",
      "Average loss:0.5579578760597441 at epoch:9  and accuracy is : 0.592592592593\n",
      "Average loss:0.552448151840104 at epoch:10  and accuracy is : 0.592592592593\n",
      "Average loss:0.5481946253114276 at epoch:11  and accuracy is : 0.592592592593\n",
      "Average loss:0.5448801037338045 at epoch:12  and accuracy is : 0.592592592593\n",
      "Average loss:0.5422687381505966 at epoch:13  and accuracy is : 0.62962962963\n",
      "Average loss:0.5401864813433753 at epoch:14  and accuracy is : 0.62962962963\n",
      "Average loss:0.5385055409537421 at epoch:15  and accuracy is : 0.62962962963\n",
      "Average loss:0.5371323741144605 at epoch:16  and accuracy is : 0.62962962963\n",
      "Average loss:0.5359983874691857 at epoch:17  and accuracy is : 0.62962962963\n",
      "Average loss:0.5350529534949197 at epoch:18  and accuracy is : 0.62962962963\n",
      "Average loss:0.5342583176162508 at epoch:19  and accuracy is : 0.62962962963\n",
      "Average loss:0.5335859855016073 at epoch:20  and accuracy is : 0.62962962963\n",
      "Average loss:0.5330140590667725 at epoch:21  and accuracy is : 0.62962962963\n",
      "Average loss:0.5325254433684878 at epoch:22  and accuracy is : 0.62962962963\n",
      "Average loss:0.5321066164308124 at epoch:23  and accuracy is : 0.62962962963\n",
      "Average loss:0.531746592786577 at epoch:24  and accuracy is : 0.62962962963\n",
      "Average loss:0.5314364731311798 at epoch:25  and accuracy is : 0.62962962963\n",
      "Average loss:0.5311688565545611 at epoch:26  and accuracy is : 0.62962962963\n",
      "Average loss:0.5309375822544098 at epoch:27  and accuracy is : 0.62962962963\n",
      "Average loss:0.5307374795277914 at epoch:28  and accuracy is : 0.62962962963\n",
      "Average loss:0.5305641558435228 at epoch:29  and accuracy is : 0.62962962963\n",
      "Average loss:0.53041386935446 at epoch:30  and accuracy is : 0.62962962963\n",
      "Average loss:0.5302834543916914 at epoch:31  and accuracy is : 0.62962962963\n",
      "Average loss:0.5301701840427187 at epoch:32  and accuracy is : 0.62962962963\n",
      "Average loss:0.5300717386934493 at epoch:33  and accuracy is : 0.62962962963\n",
      "Average loss:0.5299860835075378 at epoch:34  and accuracy is : 0.62962962963\n",
      "Average loss:0.5299115346537696 at epoch:35  and accuracy is : 0.62962962963\n",
      "Average loss:0.529846578836441 at epoch:36  and accuracy is : 0.62962962963\n",
      "Average loss:0.5297899428341124 at epoch:37  and accuracy is : 0.62962962963\n",
      "Average loss:0.5297405223051707 at epoch:38  and accuracy is : 0.62962962963\n",
      "Average loss:0.5296973685423533 at epoch:39  and accuracy is : 0.62962962963\n",
      "Average loss:0.5296596421135796 at epoch:40  and accuracy is : 0.62962962963\n",
      "Average loss:0.5296266277631124 at epoch:41  and accuracy is : 0.62962962963\n",
      "Average loss:0.52959772447745 at epoch:42  and accuracy is : 0.62962962963\n",
      "Average loss:0.5295723925034205 at epoch:43  and accuracy is : 0.62962962963\n",
      "Average loss:0.5295501682493422 at epoch:44  and accuracy is : 0.62962962963\n",
      "Average loss:0.5295306477281783 at epoch:45  and accuracy is : 0.62962962963\n",
      "Average loss:0.5295134716563754 at epoch:46  and accuracy is : 0.62962962963\n",
      "Average loss:0.529498365190294 at epoch:47  and accuracy is : 0.62962962963\n",
      "Average loss:0.5294850402408176 at epoch:48  and accuracy is : 0.62962962963\n",
      "Average loss:0.5294732650121053 at epoch:49  and accuracy is : 0.62962962963\n",
      "Average loss:0.5294628739356995 at epoch:50  and accuracy is : 0.62962962963\n",
      "Average loss:0.5294536799192429 at epoch:51  and accuracy is : 0.62962962963\n",
      "Average loss:0.5294455157385932 at epoch:52  and accuracy is : 0.62962962963\n",
      "Average loss:0.5294382787413068 at epoch:53  and accuracy is : 0.62962962963\n",
      "Average loss:0.5294318182600869 at epoch:54  and accuracy is : 0.62962962963\n",
      "Average loss:0.5294260813130273 at epoch:55  and accuracy is : 0.62962962963\n",
      "Average loss:0.5294209569692612 at epoch:56  and accuracy is : 0.62962962963\n",
      "Average loss:0.5294163773457209 at epoch:57  and accuracy is : 0.62962962963\n",
      "Average loss:0.5294122629695468 at epoch:58  and accuracy is : 0.62962962963\n",
      "Average loss:0.5294085741043091 at epoch:59  and accuracy is : 0.62962962963\n",
      "Average loss:0.5294052412112554 at epoch:60  and accuracy is : 0.62962962963\n",
      "Average loss:0.5294022560119629 at epoch:61  and accuracy is : 0.62962962963\n",
      "Average loss:0.529399550623364 at epoch:62  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293971002101898 at epoch:63  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293948815928565 at epoch:64  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293928533792496 at epoch:65  and accuracy is : 0.62962962963\n",
      "Average loss:0.529391015569369 at epoch:66  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293893251154158 at epoch:67  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293877704275979 at epoch:68  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293863531615999 at epoch:69  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293850484821532 at epoch:70  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293838630119959 at epoch:71  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293827371464835 at epoch:72  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293817222118378 at epoch:73  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293807768159442 at epoch:74  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293798976474338 at epoch:75  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293790847063065 at epoch:76  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293783247470856 at epoch:77  and accuracy is : 0.62962962963\n",
      "Average loss:0.529377614458402 at epoch:78  and accuracy is : 0.62962962963\n",
      "Average loss:0.529376948873202 at epoch:79  and accuracy is : 0.62962962963\n",
      "Average loss:0.529376337925593 at epoch:80  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293757501575682 at epoch:81  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293752037816577 at epoch:82  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293747037649155 at epoch:83  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293742335504956 at epoch:84  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293737832042906 at epoch:85  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293733576933543 at epoch:86  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293729719188478 at epoch:87  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293726027011871 at epoch:88  and accuracy is : 0.62962962963\n",
      "Average loss:0.529372266597218 at epoch:89  and accuracy is : 0.62962962963\n",
      "Average loss:0.529371922214826 at epoch:90  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293716324700249 at epoch:91  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293713377581702 at epoch:92  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293710745043225 at epoch:93  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293708195288976 at epoch:94  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293705893887414 at epoch:95  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293703675270081 at epoch:96  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293701473209593 at epoch:97  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293699618842866 at epoch:98  and accuracy is : 0.62962962963\n",
      "Average loss:0.5293697764476141 at epoch:99  and accuracy is : 0.62962962963\n",
      "Total time: 0.755375862121582 seconds\n",
      "Optimization Finished!\n",
      "Final Accuracy is : 0.62962962963\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(dtype = np.float32, shape = [None, 9], name='X')\n",
    "Y = tf.placeholder(dtype = np.float32, shape = [None, 2], name='Y')\n",
    "\n",
    "W = tf.Variable(tf.random_normal([9, 2]), name='W')\n",
    "b = tf.Variable(tf.zeros([2]), name='b')\n",
    "\n",
    "logits = tf.matmul(X, W) + b\n",
    "\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(labels = Y, logits = logits)\n",
    "\n",
    "loss = tf.reduce_mean(entropy)\n",
    "\n",
    "preds = tf.nn.softmax(logits)\n",
    "correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\t\n",
    "    n_batches = int(len(train_data)/batch_size)\n",
    "    for i in range(n_epochs): \n",
    "        total_loss = 0\n",
    "\n",
    "        for index in range(n_batches):\n",
    "            \n",
    "            X_batch = train_data[index*batch_size:(index+1)*batch_size]\n",
    "            Y_batch = train_label[index*batch_size:(index+1)*batch_size]\n",
    "            \n",
    "            _, loss_batch= sess.run([optimizer, loss], feed_dict={X: X_batch, Y: Y_batch})\n",
    "            total_loss += loss_batch\n",
    "            \n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data, Y: test_label})\n",
    "        print('Average loss:{0} at epoch:{1}'.format(total_loss/n_batches, i), ' and accuracy is :', test_accuracy / len(test_label))\n",
    "        \n",
    "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "    print('Optimization Finished!')\n",
    "    \n",
    "    total_accuracy = sess.run(accuracy, feed_dict={X: test_data, Y: test_label})\n",
    "    print('Final Accuracy is :', test_accuracy / len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
